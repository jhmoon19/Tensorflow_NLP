{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b65a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:07<00:00,  2.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 60.37it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 102.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 84.01it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 101.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from preprocess import *\n",
    "import os\n",
    "\n",
    "PATH = 'data_in/ChatBotData.csv_short'\n",
    "VOCAB_PATH = 'data_in/vocabulary.txt'\n",
    "\n",
    "# 이미 존재하는 v1 vocab 파일 삭제\n",
    "if os.path.exists(VOCAB_PATH):\n",
    "    os.remove(VOCAB_PATH)\n",
    "    \n",
    "# 입력: 질문 리스트, 출력: 대답 리스트\n",
    "inputs, outputs = load_data(PATH)\n",
    "\n",
    "# 단어-정수 매핑사전, 정수-단어 매핑사전, 사전크기\n",
    "char2idx, idx2char, vocab_size = \\\n",
    "  load_vocabulary(PATH, VOCAB_PATH, tokenize_as_morph=True)\n",
    "\n",
    "# 넘파이 배열(asarray), (패딩전) 입력 시퀀스 길이 리스트\n",
    "# 각 질문 문장을 정수 벡터화 \n",
    "index_inputs, input_seq_len = \\\n",
    "  enc_processing(inputs, char2idx, tokenize_as_morph=True)\n",
    "# 각 대답 문장을 정수 벡터화 (\"<SOS>\"로 시작)\n",
    "index_outputs, output_seq_len = \\\n",
    "  dec_output_processing(outputs, char2idx, tokenize_as_morph=True)\n",
    "# \"<END>\" 로 끝나는 디코더 타깃값\n",
    "index_targets = \\\n",
    "  dec_target_processing(outputs, char2idx, tokenize_as_morph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c831f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_configs = {}\n",
    "data_configs['char2idx'] = char2idx # 단어-정수 사전\n",
    "data_configs['idx2char'] = idx2char # 정수-단어 사전\n",
    "data_configs['vocab_size'] = vocab_size # 125\n",
    "\n",
    "\"\"\" .py파일 import *시 '변수명'도 모두 불러와짐! \"\"\"\n",
    "data_configs['pad_symbol'] = PAD # \"<PAD>\"\n",
    "data_configs['std_symbol'] = STD # \"<SOS>\"\n",
    "data_configs['end_symbol'] = END # \"<END>\"\n",
    "data_configs['unk_symbol'] = UNK # \"<UNK>\"\n",
    "\n",
    "DATA_IN_PATH = './data_in/'\n",
    "TRAIN_INPUTS = 'train_inputs.npy'\n",
    "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
    "TRAIN_TARGETS = 'train_targets.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "# 입력 시퀀스/출력,타깃 시퀀스 넘파이 배열 저장 \n",
    "np.save(open(DATA_IN_PATH + TRAIN_INPUTS, 'wb'), index_inputs)\n",
    "np.save(open(DATA_IN_PATH + TRAIN_OUTPUTS, 'wb'), index_outputs)\n",
    "np.save(open(DATA_IN_PATH + TRAIN_TARGETS, 'wb'), index_targets)\n",
    "\n",
    "# 데이터 정보 사전 json 파일 dump\n",
    "json.dump(data_configs, open(DATA_IN_PATH + DATA_CONFIGS, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc346486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
