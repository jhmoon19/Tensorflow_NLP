{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca7cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2600c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "TRAIN_INPUTS = 'train_inputs.npy'\n",
    "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
    "TRAIN_TARGETS = 'train_targets.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)\n",
    "\n",
    "index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n",
    "index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS, 'rb'))\n",
    "index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS, 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))\n",
    "\n",
    "# 각 시퀀스 길이 확인\n",
    "print(len(index_inputs), len(index_outputs), len(index_targets))\n",
    "\n",
    "MODEL_NAME = 'seq2seq_kor'\n",
    "BATCH_SIZE = 2\n",
    "MAX_SEQUENCE = 25\n",
    "EPOCH = 30\n",
    "UNITS = 1024 # GRU rnn의 결과 차원\n",
    "EMBEDDING_DIM = 256\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "char2idx = prepro_configs['char2idx']\n",
    "idx2char = prepro_configs['idx2char']\n",
    "std_index = prepro_configs['std_symbol'] # \"<SOS>\"\n",
    "end_index = prepro_configs['end_symbol'] # \"<END>\"\n",
    "vocab_size = prepro_configs['vocab_size'] # 111"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5621c7b",
   "metadata": {},
   "source": [
    "# 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d29ed8",
   "metadata": {},
   "source": [
    "## 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ecb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz # 2\n",
    "        self.enc_units = enc_units # 1024\n",
    "        self.vocab_size = vocab_size # 111\n",
    "        self.embedding_dim = embedding_dim # 256\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                      return_sequences=True,\n",
    "                                      return_state=True,\n",
    "                                      recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self, inp):\n",
    "        return tf.zeros((tf.shape(inp)[0], self.enc_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3a9792",
   "metadata": {},
   "source": [
    "## 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a66dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        \n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w1 = tf.keras.layers.Dense(units)\n",
    "        self.w2 = tf.keras.layers.Dense(units)\n",
    "        self.v = tf.keras.layers.Dense(1)\n",
    "        \"\"\" w1, w2, v는 학습을 통해 최적화됨!! \"\"\"\n",
    "\n",
    "    def call(self, query, values):\n",
    "        \"\"\"\n",
    "        query: 인코더 GRU rnn의 은닉상태값 \n",
    "        values: 인코더 GRU rnn의 결과값\n",
    "        \"\"\"\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        # query를 w2에 행렬곱할 수 있는 형태를 만듦.\n",
    "        \n",
    "        score = self.v(tf.nn.tanh(\n",
    "            self.w1(values) + self.w2(hidden_with_time_axis)))\n",
    "        # 1차원의 벡터값 나옴\n",
    "        \n",
    "        # 어텐션 가중치\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        # 모델이 중요하다고 판단하는 값은 1에, 영향도 떨어질수록 0에 가까운 값\n",
    "        \n",
    "        context_vector = attention_weights * values\n",
    "        # 인코더 결과값 중 1에 가까운 값은 커지고, 0에 가까운 값은 작아짐\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        \"\"\" 새로운 인코더 순환 신경망 결과값 만들어서 디코더에 전달!! \"\"\"\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8bc69",
   "metadata": {},
   "source": [
    "## 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "513aedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
    "                                                  self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                      return_sequences=True,\n",
    "                                      return_state=True,\n",
    "                                      recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(self.vocab_size)\n",
    "        \n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        \n",
    "        # 1. 인코더 결과값에 어텐션 가중치 적용해서 새로운 결과값 \"문맥 벡터\" 만듦\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        # context_vector : (20, 1024)\n",
    "        \n",
    "        # 2. 디코더 입력값 임베딩 \n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # 3. 문맥벡터와 디코더 입력 임베딩값을 연결 \n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        # tf.concat([(20, 1, 1024), (20, 1, 256)], axis=-1)\n",
    "        # concat 결과: (20, 1, 1280)\n",
    "        \n",
    "        # 4. 연결한 것을 GRU rnn \n",
    "        output, state = self.gru(x)\n",
    "        # output: (20, 1, 1024)\n",
    "        # state: (20, 1024) - 디코더 최종 은닉상태 행렬\n",
    "        \n",
    "        # 5. GRU 결과 reshape\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        # tf.reshape(output, (-1, 1024))\n",
    "        # output: (20, 1024)\n",
    "        \n",
    "        # 6. 선형 층 통과 \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        # 디코더 출력값, 디코더 최종 은닉상태, 어텐션 가중치 \n",
    "        return x, state, attention_weights\n",
    "        # x: (20, 111)\n",
    "        # state: (20, 1024)\n",
    "        # attention_weights: (20, 25, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651cf1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask\n",
    "    acc = train_accuracy(real, pred)\n",
    "    \n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2222a16",
   "metadata": {},
   "source": [
    "## 시퀀스 투 시퀀스 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a53e0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, batch_sz, end_token_idx=2):\n",
    "        \n",
    "        super(seq2seq, self).__init__()\n",
    "        \n",
    "        self.end_token_idx = end_token_idx\n",
    "        self.encoder = Encoder(vocab_size, embedding_dim, enc_units, batch_sz)\n",
    "        self.decoder = Decoder(vocab_size, embedding_dim, dec_units, batch_sz)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        inp, tar = x # index_inputs, index_outputs\n",
    "        \n",
    "        enc_hidden = self.encoder.initialize_hidden_state(inp)\n",
    "        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
    "        \n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        predict_tokens = list()\n",
    "        \n",
    "        for t in range(0, tar.shape[1]): # range(0, 25)\n",
    "            # 각 타임스텝마다 (t: 0~24)\n",
    "            dec_input = tf.dtypes.cast(tf.expand_dims(tar[:,t],1), tf.float32)\n",
    "            \n",
    "            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            # 마지막 값은 \"어텐션 가중치\"\n",
    "            \n",
    "            predict_tokens.append(tf.dtypes.cast(predictions, tf.float32))\n",
    "            \n",
    "        return tf.stack(predict_tokens, axis=1)\n",
    "    \n",
    "    # 임의의 입력에 대한 모델의 결과값 확인하기 위한 테스트 목적 함수\n",
    "    def inference(self, x):\n",
    "        \n",
    "        inp = x  # test_index_inputs\n",
    "#         array([[41, 59, 56, 61,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "#          0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
    "#         (1, 25)\n",
    "\n",
    "        # 질문을 받아서 은닉상태를 초기화하고 \n",
    "        enc_hidden = self.encoder.initialize_hidden_state(inp)\n",
    "        # <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>\n",
    "        \n",
    "        # 해당 질문과 은닉상태로 GRU rnn 인코딩을 진행한다. \n",
    "        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
    "        # enc_output = (1, 25, 1024) : 인코더 출력\n",
    "        # enc_hidden = (1, 1024) : 최종 은닉상태벡터\n",
    "        \n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        dec_input = tf.expand_dims([char2idx[std_index]], 1) # ([1],1)\n",
    "        # <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[1]])>\n",
    "        \n",
    "        predict_tokens = list()\n",
    "        \n",
    "        for t in range(0, MAX_SEQUENCE): # range(0, 25)\n",
    "            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            # decoder([[1]], 인코더 최종 은닉상태, 인코더 출력) 시작\n",
    "            # \"<SOS>\" 의 정수인덱스로 예측 문장 시작\n",
    "            \n",
    "            predict_token = tf.argmax(predictions[0]) # 최대값의 위치 (111개 단어 중)\n",
    "            # <tf.Tensor: shape=(), dtype=int64, numpy=101>\n",
    "            \n",
    "            # \"<END>\" 만나면 반복 멈춤\n",
    "            if predict_token == self.end_token_idx: # 2\n",
    "                break\n",
    "                \n",
    "            predict_tokens.append(predict_token)\n",
    "            dec_input = tf.dtypes.cast(tf.expand_dims([predict_token], 0), tf.float32)\n",
    "            # ex. <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[101.]], dtype=float32)>\n",
    "            # 디코더를 거쳐나온 predictions 값이 가장 큰 위치를 실수화한 것\n",
    "            \n",
    "        return tf.stack(predict_tokens, axis=0).numpy()\n",
    "        # ex. array([49, 45, 34,  3], dtype=int64)\n",
    "        # idx2char 사전으로 해독하고, ' '.join시키면 답변 문장 나옴!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0957455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = seq2seq(vocab_size, EMBEDDING_DIM, UNITS, UNITS, BATCH_SIZE, char2idx[end_index])\n",
    "model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(1e-3), metrics=[accuracy])\n",
    "# model.run_eagerly = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657508d",
   "metadata": {},
   "source": [
    "# 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c1982b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7766 - accuracy: 0.8416\n",
      "Epoch 1: val_accuracy improved from -inf to 0.87400, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 77s 2s/step - loss: 0.7766 - accuracy: 0.8416 - val_loss: 0.5426 - val_accuracy: 0.8740\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.8775\n",
      "Epoch 2: val_accuracy improved from 0.87400 to 0.87800, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 0.6081 - accuracy: 0.8775 - val_loss: 0.4799 - val_accuracy: 0.8780\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5079 - accuracy: 0.8819\n",
      "Epoch 3: val_accuracy improved from 0.87800 to 0.88400, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.5079 - accuracy: 0.8819 - val_loss: 0.4123 - val_accuracy: 0.8840\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4536 - accuracy: 0.8863\n",
      "Epoch 4: val_accuracy improved from 0.88400 to 0.88750, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 345ms/step - loss: 0.4536 - accuracy: 0.8863 - val_loss: 0.3825 - val_accuracy: 0.8875\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4189 - accuracy: 0.8888\n",
      "Epoch 5: val_accuracy improved from 0.88750 to 0.88960, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 341ms/step - loss: 0.4189 - accuracy: 0.8888 - val_loss: 0.3408 - val_accuracy: 0.8896\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.8897\n",
      "Epoch 6: val_accuracy improved from 0.88960 to 0.89133, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 349ms/step - loss: 0.3810 - accuracy: 0.8897 - val_loss: 0.2967 - val_accuracy: 0.8913\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.8922\n",
      "Epoch 7: val_accuracy improved from 0.89133 to 0.89314, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 347ms/step - loss: 0.3437 - accuracy: 0.8922 - val_loss: 0.2708 - val_accuracy: 0.8931\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3101 - accuracy: 0.8949\n",
      "Epoch 8: val_accuracy improved from 0.89314 to 0.89625, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 350ms/step - loss: 0.3101 - accuracy: 0.8949 - val_loss: 0.2469 - val_accuracy: 0.8963\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.8978\n",
      "Epoch 9: val_accuracy improved from 0.89625 to 0.89978, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 358ms/step - loss: 0.2733 - accuracy: 0.8978 - val_loss: 0.2249 - val_accuracy: 0.8998\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.9018\n",
      "Epoch 10: val_accuracy improved from 0.89978 to 0.90420, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 362ms/step - loss: 0.2475 - accuracy: 0.9018 - val_loss: 0.1919 - val_accuracy: 0.9042\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.9066\n",
      "Epoch 11: val_accuracy improved from 0.90420 to 0.90891, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 360ms/step - loss: 0.2259 - accuracy: 0.9066 - val_loss: 0.1847 - val_accuracy: 0.9089\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.9112\n",
      "Epoch 12: val_accuracy improved from 0.90891 to 0.91333, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 368ms/step - loss: 0.1920 - accuracy: 0.9112 - val_loss: 0.1710 - val_accuracy: 0.9133\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9152\n",
      "Epoch 13: val_accuracy improved from 0.91333 to 0.91692, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 362ms/step - loss: 0.1777 - accuracy: 0.9152 - val_loss: 0.1936 - val_accuracy: 0.9169\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9186\n",
      "Epoch 14: val_accuracy improved from 0.91692 to 0.92000, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 385ms/step - loss: 0.1647 - accuracy: 0.9186 - val_loss: 0.1225 - val_accuracy: 0.9200\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1486 - accuracy: 0.9214\n",
      "Epoch 15: val_accuracy improved from 0.92000 to 0.92253, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 392ms/step - loss: 0.1486 - accuracy: 0.9214 - val_loss: 0.1410 - val_accuracy: 0.9225\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9238\n",
      "Epoch 16: val_accuracy improved from 0.92253 to 0.92500, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 4s 389ms/step - loss: 0.1395 - accuracy: 0.9238 - val_loss: 0.1188 - val_accuracy: 0.9250\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9261\n",
      "Epoch 17: val_accuracy improved from 0.92500 to 0.92706, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 375ms/step - loss: 0.1280 - accuracy: 0.9261 - val_loss: 0.1277 - val_accuracy: 0.9271\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.9280\n",
      "Epoch 18: val_accuracy improved from 0.92706 to 0.92889, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 3s 360ms/step - loss: 0.1299 - accuracy: 0.9280 - val_loss: 0.1241 - val_accuracy: 0.9289\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.9296\n",
      "Epoch 19: val_accuracy improved from 0.92889 to 0.93032, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 4s 442ms/step - loss: 0.1217 - accuracy: 0.9296 - val_loss: 0.1254 - val_accuracy: 0.9303\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9312\n",
      "Epoch 20: val_accuracy improved from 0.93032 to 0.93180, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 4s 453ms/step - loss: 0.1176 - accuracy: 0.9312 - val_loss: 0.1117 - val_accuracy: 0.9318\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.9325\n",
      "Epoch 21: val_accuracy improved from 0.93180 to 0.93324, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 4s 439ms/step - loss: 0.1130 - accuracy: 0.9325 - val_loss: 0.1241 - val_accuracy: 0.9332\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9340\n",
      "Epoch 22: val_accuracy improved from 0.93324 to 0.93473, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 4s 454ms/step - loss: 0.1097 - accuracy: 0.9340 - val_loss: 0.1146 - val_accuracy: 0.9347\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9354\n",
      "Epoch 23: val_accuracy improved from 0.93473 to 0.93609, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 4s 466ms/step - loss: 0.0973 - accuracy: 0.9354 - val_loss: 0.1220 - val_accuracy: 0.9361\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9369\n",
      "Epoch 24: val_accuracy improved from 0.93609 to 0.93758, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 4s 474ms/step - loss: 0.0833 - accuracy: 0.9369 - val_loss: 0.1275 - val_accuracy: 0.9376\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9383\n",
      "Epoch 25: val_accuracy improved from 0.93758 to 0.93912, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 4s 466ms/step - loss: 0.0630 - accuracy: 0.9383 - val_loss: 0.1414 - val_accuracy: 0.9391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9401\n",
      "Epoch 26: val_accuracy improved from 0.93912 to 0.94092, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 4s 508ms/step - loss: 0.0452 - accuracy: 0.9401 - val_loss: 0.1717 - val_accuracy: 0.9409\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9420\n",
      "Epoch 27: val_accuracy improved from 0.94092 to 0.94281, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 4s 495ms/step - loss: 0.0259 - accuracy: 0.9420 - val_loss: 0.1945 - val_accuracy: 0.9428\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9437\n",
      "Epoch 28: val_accuracy improved from 0.94281 to 0.94457, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 5s 538ms/step - loss: 0.0168 - accuracy: 0.9437 - val_loss: 0.2029 - val_accuracy: 0.9446\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9453\n",
      "Epoch 29: val_accuracy improved from 0.94457 to 0.94607, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 5s 586ms/step - loss: 0.0392 - accuracy: 0.9453 - val_loss: 0.2008 - val_accuracy: 0.9461\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9468\n",
      "Epoch 30: val_accuracy improved from 0.94607 to 0.94747, saving model to ./data_out/seq2seq_kor\\weights.h5\n",
      "9/9 [==============================] - 6s 619ms/step - loss: 0.0272 - accuracy: 0.9468 - val_loss: 0.1995 - val_accuracy: 0.9475\n"
     ]
    }
   ],
   "source": [
    "PATH = DATA_OUT_PATH + MODEL_NAME\n",
    "\n",
    "if not(os.path.isdir(PATH)):\n",
    "    os.makedirs(os.path.join(PATH))\n",
    "    \n",
    "checkpoint_path = DATA_OUT_PATH + MODEL_NAME + '/weights.h5'\n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1,\n",
    "    save_best_only=True, save_weights_only=True)\n",
    "\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy',\n",
    "                                  min_delta = 0.0001,\n",
    "                                  patience=10)\n",
    "\n",
    "history = model.fit([index_inputs, index_outputs], index_targets,\n",
    "                   batch_size = BATCH_SIZE, epochs=EPOCH,\n",
    "                   validation_split=VALIDATION_SPLIT,\n",
    "                   callbacks=[earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5a5df",
   "metadata": {},
   "source": [
    "# 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19d4f26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49 45 34  3]\n",
      "평소에 필요한 것 <UNK>\n"
     ]
    }
   ],
   "source": [
    "SAVE_FILE_NM = 'weights.h5'\n",
    "model.load_weights(os.path.join(DATA_OUT_PATH, MODEL_NAME, SAVE_FILE_NM))\n",
    "\n",
    "query = \"남자친구 승진 선물로 뭐가 좋을까?\"\n",
    "\n",
    "# preprocess.py 의 함수 이용! \n",
    "test_index_inputs, _ = enc_processing([query], char2idx)\n",
    "predict_tokens = model.inference(test_index_inputs)\n",
    "print(predict_tokens)\n",
    "\n",
    "print(' '.join([idx2char[str(t)] for t in predict_tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1fa06f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 45, 34,  3], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inference(test_index_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ab24df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 8.4215831e-03, -1.1196337e-03,  1.4138895e-03, ...,\n",
       "          1.6215544e-02,  1.0359879e-02, -4.1585290e-03],\n",
       "        [ 7.9158768e-03, -1.1241965e-03,  1.3373462e-03, ...,\n",
       "          1.6100917e-02,  1.0241423e-02, -4.1347970e-03],\n",
       "        [ 8.4461328e-03, -1.2108093e-03,  1.3304802e-03, ...,\n",
       "          1.6038792e-02,  9.7769313e-03, -3.8001370e-03],\n",
       "        ...,\n",
       "        [ 7.8215245e-03, -2.5606330e-04,  2.3081205e-03, ...,\n",
       "          1.6792014e-02,  1.0876923e-02, -4.1219615e-03],\n",
       "        [ 7.6563433e-03,  2.8635876e-04,  1.9904436e-03, ...,\n",
       "          1.7501252e-02,  1.0738020e-02, -4.1031847e-03],\n",
       "        [ 8.2794465e-03, -9.4826508e-05,  2.0592671e-03, ...,\n",
       "          1.6905840e-02,  1.0454825e-02, -4.5564095e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 0.00661545, -0.00986471, -0.01042728, ..., -0.00091787,\n",
       "          0.01066955,  0.00064627],\n",
       "        [ 0.00610968, -0.0098733 , -0.01050336, ..., -0.00103147,\n",
       "          0.01055308,  0.00066738],\n",
       "        [-0.00231548, -0.00279578,  0.01652032, ...,  0.00016517,\n",
       "          0.00491573, -0.00860703],\n",
       "        ...,\n",
       "        [ 0.00556597, -0.01165456, -0.00510196, ...,  0.01145225,\n",
       "          0.002537  , -0.0032943 ],\n",
       "        [ 0.02067161, -0.00147539,  0.0019046 , ..., -0.00662989,\n",
       "          0.0188128 , -0.00428717],\n",
       "        [ 0.00456317,  0.00491011, -0.01423219, ...,  0.00155503,\n",
       "          0.00544226, -0.00492733]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 0.00861379, -0.00406231, -0.00529434, ..., -0.00433211,\n",
       "         -0.00108544, -0.01641311],\n",
       "        [ 0.00811007, -0.00407309, -0.00537361, ..., -0.00444377,\n",
       "         -0.00120444, -0.01638845],\n",
       "        [ 0.0151054 , -0.00696013,  0.00120551, ..., -0.00647516,\n",
       "          0.00424876, -0.00559707],\n",
       "        ...,\n",
       "        [ 0.0076752 ,  0.00347092, -0.00288762, ..., -0.00184423,\n",
       "          0.0067483 , -0.00397197],\n",
       "        [ 0.00437494, -0.00502803, -0.00556982, ..., -0.00056793,\n",
       "         -0.00231336,  0.00553934],\n",
       "        [ 0.00717526,  0.01048298,  0.01357536, ..., -0.0053884 ,\n",
       "          0.00989118,  0.00419118]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 0.01919523, -0.0072148 ,  0.00254487, ..., -0.00271757,\n",
       "         -0.00047074, -0.00261549],\n",
       "        [ 0.01868915, -0.00722027,  0.00246467, ..., -0.00283071,\n",
       "         -0.00058828, -0.00259624],\n",
       "        [ 0.01034969, -0.0032175 , -0.00079809, ..., -0.00533094,\n",
       "          0.00039486, -0.00842263],\n",
       "        ...,\n",
       "        [ 0.01448572, -0.00601053,  0.00218597, ..., -0.00572023,\n",
       "          0.00534665, -0.00591294],\n",
       "        [ 0.01432125, -0.00546723,  0.00186372, ..., -0.00500873,\n",
       "          0.005206  , -0.0058998 ],\n",
       "        [ 0.01493975, -0.00584214,  0.00193242, ..., -0.00560578,\n",
       "          0.0049254 , -0.00635042]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.5081335e-02, -6.8739317e-03,  1.2883184e-03, ...,\n",
       "         -6.2926030e-03,  4.8302906e-03, -5.9519266e-03],\n",
       "        [ 1.4575069e-02, -6.8778917e-03,  1.2090775e-03, ...,\n",
       "         -6.4064655e-03,  4.7106585e-03, -5.9299855e-03],\n",
       "        [ 1.0349688e-02, -3.2174964e-03, -7.9808524e-04, ...,\n",
       "         -5.3309374e-03,  3.9486762e-04, -8.4226318e-03],\n",
       "        ...,\n",
       "        [ 9.7245323e-03, -2.2657672e-03,  1.8538022e-04, ...,\n",
       "         -4.5754709e-03,  1.4937276e-03, -8.7402184e-03],\n",
       "        [ 9.5591256e-03, -1.7233831e-03, -1.3510196e-04, ...,\n",
       "         -3.8670464e-03,  1.3564359e-03, -8.7261535e-03],\n",
       "        [ 1.0181941e-02, -2.1086507e-03, -7.0606242e-05, ...,\n",
       "         -4.4569760e-03,  1.0706966e-03, -9.1783619e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.0327302e-02, -3.1297598e-03, -7.1085145e-04, ...,\n",
       "         -5.1538181e-03,  9.7646029e-04, -8.7797698e-03],\n",
       "        [ 9.8198391e-03, -3.1365631e-03, -7.8992173e-04, ...,\n",
       "         -5.2703894e-03,  8.5715321e-04, -8.7568723e-03],\n",
       "        [ 1.0349687e-02, -3.2174955e-03, -7.9808512e-04, ...,\n",
       "         -5.3309374e-03,  3.9486738e-04, -8.4226327e-03],\n",
       "        ...,\n",
       "        [ 9.7245341e-03, -2.2657635e-03,  1.8538465e-04, ...,\n",
       "         -4.5754677e-03,  1.4937260e-03, -8.7402249e-03],\n",
       "        [ 9.5591238e-03, -1.7233798e-03, -1.3510673e-04, ...,\n",
       "         -3.8670504e-03,  1.3564348e-03, -8.7261535e-03],\n",
       "        [ 1.0181943e-02, -2.1086466e-03, -7.0602051e-05, ...,\n",
       "         -4.4569774e-03,  1.0706941e-03, -9.1783628e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975980e-03, -7.10849534e-04, ...,\n",
       "         -5.15382038e-03,  9.76456795e-04, -8.77976976e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496863e-02, -3.21749505e-03, -7.98085006e-04, ...,\n",
       "         -5.33093698e-03,  3.94866103e-04, -8.42263177e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819392e-02, -2.10864842e-03, -7.06034480e-05, ...,\n",
       "         -4.45697783e-03,  1.07069453e-03, -9.17835906e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975841e-03, -7.10851164e-04, ...,\n",
       "         -5.15381712e-03,  9.76456329e-04, -8.77977163e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496881e-02, -3.21749644e-03, -7.98084773e-04, ...,\n",
       "         -5.33093512e-03,  3.94865987e-04, -8.42263363e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819411e-02, -2.10864749e-03, -7.06035644e-05, ...,\n",
       "         -4.45697596e-03,  1.07069197e-03, -9.17836092e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975980e-03, -7.10849534e-04, ...,\n",
       "         -5.15382038e-03,  9.76456795e-04, -8.77976976e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496872e-02, -3.21749691e-03, -7.98085588e-04, ...,\n",
       "         -5.33093791e-03,  3.94865521e-04, -8.42263177e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819392e-02, -2.10864749e-03, -7.06048450e-05, ...,\n",
       "         -4.45697689e-03,  1.07069348e-03, -9.17835906e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975841e-03, -7.10851164e-04, ...,\n",
       "         -5.15381712e-03,  9.76456329e-04, -8.77977163e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496891e-02, -3.21749644e-03, -7.98085704e-04, ...,\n",
       "         -5.33093745e-03,  3.94867966e-04, -8.42262991e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819430e-02, -2.10864656e-03, -7.06020510e-05, ...,\n",
       "         -4.45697736e-03,  1.07069407e-03, -9.17836279e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975980e-03, -7.10849534e-04, ...,\n",
       "         -5.15382038e-03,  9.76456795e-04, -8.77976976e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496863e-02, -3.21749644e-03, -7.98084540e-04, ...,\n",
       "         -5.33093885e-03,  3.94866802e-04, -8.42263177e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819392e-02, -2.10864842e-03, -7.06034480e-05, ...,\n",
       "         -4.45697783e-03,  1.07069453e-03, -9.17835906e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975841e-03, -7.10851164e-04, ...,\n",
       "         -5.15381712e-03,  9.76456329e-04, -8.77977163e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496872e-02, -3.21749551e-03, -7.98085122e-04, ...,\n",
       "         -5.33093745e-03,  3.94867384e-04, -8.42263270e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819411e-02, -2.10864749e-03, -7.06035644e-05, ...,\n",
       "         -4.45697596e-03,  1.07069197e-03, -9.17836092e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975980e-03, -7.10849534e-04, ...,\n",
       "         -5.15382038e-03,  9.76456795e-04, -8.77976976e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496863e-02, -3.21749505e-03, -7.98085006e-04, ...,\n",
       "         -5.33093698e-03,  3.94866103e-04, -8.42263177e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819392e-02, -2.10864749e-03, -7.06048450e-05, ...,\n",
       "         -4.45697689e-03,  1.07069348e-03, -9.17835906e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975841e-03, -7.10851164e-04, ...,\n",
       "         -5.15381712e-03,  9.76456329e-04, -8.77977163e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496881e-02, -3.21749644e-03, -7.98084773e-04, ...,\n",
       "         -5.33093512e-03,  3.94865987e-04, -8.42263363e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819430e-02, -2.10864656e-03, -7.06020510e-05, ...,\n",
       "         -4.45697736e-03,  1.07069407e-03, -9.17836279e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975980e-03, -7.10849534e-04, ...,\n",
       "         -5.15382038e-03,  9.76456795e-04, -8.77976976e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496872e-02, -3.21749691e-03, -7.98085588e-04, ...,\n",
       "         -5.33093791e-03,  3.94865521e-04, -8.42263177e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819392e-02, -2.10864842e-03, -7.06034480e-05, ...,\n",
       "         -4.45697783e-03,  1.07069453e-03, -9.17835906e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975841e-03, -7.10851164e-04, ...,\n",
       "         -5.15381712e-03,  9.76456329e-04, -8.77977163e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496891e-02, -3.21749644e-03, -7.98085704e-04, ...,\n",
       "         -5.33093745e-03,  3.94867966e-04, -8.42262991e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819411e-02, -2.10864749e-03, -7.06035644e-05, ...,\n",
       "         -4.45697596e-03,  1.07069197e-03, -9.17836092e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975980e-03, -7.10849534e-04, ...,\n",
       "         -5.15382038e-03,  9.76456795e-04, -8.77976976e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496863e-02, -3.21749644e-03, -7.98084540e-04, ...,\n",
       "         -5.33093885e-03,  3.94866802e-04, -8.42263177e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819392e-02, -2.10864749e-03, -7.06048450e-05, ...,\n",
       "         -4.45697689e-03,  1.07069348e-03, -9.17835906e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975841e-03, -7.10851164e-04, ...,\n",
       "         -5.15381712e-03,  9.76456329e-04, -8.77977163e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496872e-02, -3.21749551e-03, -7.98085122e-04, ...,\n",
       "         -5.33093745e-03,  3.94867384e-04, -8.42263270e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819430e-02, -2.10864656e-03, -7.06020510e-05, ...,\n",
       "         -4.45697736e-03,  1.07069407e-03, -9.17836279e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975980e-03, -7.10849534e-04, ...,\n",
       "         -5.15382038e-03,  9.76456795e-04, -8.77976976e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496863e-02, -3.21749505e-03, -7.98085006e-04, ...,\n",
       "         -5.33093698e-03,  3.94866103e-04, -8.42263177e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819392e-02, -2.10864842e-03, -7.06034480e-05, ...,\n",
       "         -4.45697783e-03,  1.07069453e-03, -9.17835906e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975841e-03, -7.10851164e-04, ...,\n",
       "         -5.15381712e-03,  9.76456329e-04, -8.77977163e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496881e-02, -3.21749644e-03, -7.98084773e-04, ...,\n",
       "         -5.33093512e-03,  3.94865987e-04, -8.42263363e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819411e-02, -2.10864749e-03, -7.06035644e-05, ...,\n",
       "         -4.45697596e-03,  1.07069197e-03, -9.17836092e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975980e-03, -7.10849534e-04, ...,\n",
       "         -5.15382038e-03,  9.76456795e-04, -8.77976976e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496872e-02, -3.21749691e-03, -7.98085588e-04, ...,\n",
       "         -5.33093791e-03,  3.94865521e-04, -8.42263177e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819392e-02, -2.10864749e-03, -7.06048450e-05, ...,\n",
       "         -4.45697689e-03,  1.07069348e-03, -9.17835906e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975841e-03, -7.10851164e-04, ...,\n",
       "         -5.15381712e-03,  9.76456329e-04, -8.77977163e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496891e-02, -3.21749644e-03, -7.98085704e-04, ...,\n",
       "         -5.33093745e-03,  3.94867966e-04, -8.42262991e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819430e-02, -2.10864656e-03, -7.06020510e-05, ...,\n",
       "         -4.45697736e-03,  1.07069407e-03, -9.17836279e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975980e-03, -7.10849534e-04, ...,\n",
       "         -5.15382038e-03,  9.76456795e-04, -8.77976976e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496863e-02, -3.21749644e-03, -7.98084540e-04, ...,\n",
       "         -5.33093885e-03,  3.94866802e-04, -8.42263177e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819392e-02, -2.10864842e-03, -7.06034480e-05, ...,\n",
       "         -4.45697783e-03,  1.07069453e-03, -9.17835906e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975841e-03, -7.10851164e-04, ...,\n",
       "         -5.15381712e-03,  9.76456329e-04, -8.77977163e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496872e-02, -3.21749551e-03, -7.98085122e-04, ...,\n",
       "         -5.33093745e-03,  3.94867384e-04, -8.42263270e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819411e-02, -2.10864749e-03, -7.06035644e-05, ...,\n",
       "         -4.45697596e-03,  1.07069197e-03, -9.17836092e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(20, 111), dtype=float32, numpy=\n",
       " array([[ 1.03272945e-02, -3.12975980e-03, -7.10849534e-04, ...,\n",
       "         -5.15382038e-03,  9.76456795e-04, -8.77976976e-03],\n",
       "        [ 9.81983915e-03, -3.13656731e-03, -7.89922662e-04, ...,\n",
       "         -5.27038937e-03,  8.57153675e-04, -8.75686947e-03],\n",
       "        [ 1.03496863e-02, -3.21749505e-03, -7.98085006e-04, ...,\n",
       "         -5.33093698e-03,  3.94866103e-04, -8.42263177e-03],\n",
       "        ...,\n",
       "        [ 9.72453039e-03, -2.26576207e-03,  1.85384648e-04, ...,\n",
       "         -4.57546767e-03,  1.49372546e-03, -8.74022394e-03],\n",
       "        [ 9.55912471e-03, -1.72338123e-03, -1.35106384e-04, ...,\n",
       "         -3.86705063e-03,  1.35643641e-03, -8.72615445e-03],\n",
       "        [ 1.01819392e-02, -2.10864749e-03, -7.06048450e-05, ...,\n",
       "         -4.45697689e-03,  1.07069348e-03, -9.17835906e-03]], dtype=float32)>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "effa2c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41, 59, 56, 61,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index_inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
