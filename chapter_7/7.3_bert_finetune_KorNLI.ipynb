{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3455acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79521c67",
   "metadata": {},
   "source": [
    "계속 [Windows 182] OsError 뜸 ...\n",
    "\n",
    "갑자기 한줄 한줄 import 시키니까 또 됨 ... ㅋㅋㅋ 뭐지...\n",
    "- import torch 따로 먼저 --> 이게 되면 됨!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af1733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "MAX_LEN = 24 * 2 # 평균 버트토큰 수 * 2\n",
    "# 문장 2개 사용해서 * 2\n",
    "\n",
    "DATA_IN_PATH = './data_in/KOR'\n",
    "DATA_OUT_PATH = './data_out/KOR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea688b",
   "metadata": {},
   "source": [
    "# KorNLI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f5991ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # dataset: train - 942808, dev - 2490\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SNLI_DF = os.path.join(DATA_IN_PATH, 'KorNLI', 'snli_1.0_train.kor.tsv')\n",
    "TRAIN_XNLI_DF = os.path.join(DATA_IN_PATH, 'KorNLI', 'multinli.train.ko.tsv')\n",
    "DEV_XNLI_DF = os.path.join(DATA_IN_PATH, 'KorNLI', 'xnli.dev.ko.tsv')\n",
    "\n",
    "train_data_snli = pd.read_csv(TRAIN_SNLI_DF, header=0, sep='\\t', quoting=3)\n",
    "train_data_xnli = pd.read_csv(TRAIN_XNLI_DF, header=0, sep='\\t', quoting=3)\n",
    "dev_data_xnli = pd.read_csv(DEV_XNLI_DF, header=0, sep='\\t', quoting=3)\n",
    "\n",
    "train_data_snli_xnli = train_data_snli.append(train_data_xnli)\n",
    "train_data_snli_xnli = train_data_snli_xnli.dropna()\n",
    "train_data_snli_xnli = train_data_snli_xnli.reset_index()\n",
    "\n",
    "dev_data_xnli = dev_data_xnli.dropna()\n",
    "\n",
    "print(\"Total # dataset: train - {}, dev - {}\".format(len(train_data_snli_xnli), len(dev_data_xnli)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42aadf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>피스티는 피즐처럼 중간 영어의 피스틴으로 시작되어 방귀를 뀌기 위해 주먹을 쥐었다.</td>\n",
       "      <td>Fiesty는 100년 동안 존재해 왔다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>피스티는 피즐처럼 중간 영어의 피스틴으로 시작되어 방귀를 뀌기 위해 주먹을 쥐었다.</td>\n",
       "      <td>Fiesty는 주먹질과는 무관하다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>진술이 더 나은 반면, 대답은 완성의 정신적 그림을 준다.</td>\n",
       "      <td>진술은 더 자세한 내용을 알려준다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>진술이 더 나은 반면, 대답은 완성의 정신적 그림을 준다.</td>\n",
       "      <td>진술이 더 나은 것은 아니다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>진술이 더 나은 반면, 대답은 완성의 정신적 그림을 준다.</td>\n",
       "      <td>진술이 더 좋다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1                sentence2  \\\n",
       "2485  피스티는 피즐처럼 중간 영어의 피스틴으로 시작되어 방귀를 뀌기 위해 주먹을 쥐었다.  Fiesty는 100년 동안 존재해 왔다.   \n",
       "2486  피스티는 피즐처럼 중간 영어의 피스틴으로 시작되어 방귀를 뀌기 위해 주먹을 쥐었다.      Fiesty는 주먹질과는 무관하다.   \n",
       "2487                진술이 더 나은 반면, 대답은 완성의 정신적 그림을 준다.      진술은 더 자세한 내용을 알려준다.   \n",
       "2488                진술이 더 나은 반면, 대답은 완성의 정신적 그림을 준다.         진술이 더 나은 것은 아니다.   \n",
       "2489                진술이 더 나은 반면, 대답은 완성의 정신적 그림을 준다.                진술이 더 좋다.   \n",
       "\n",
       "         gold_label  \n",
       "2485        neutral  \n",
       "2486  contradiction  \n",
       "2487        neutral  \n",
       "2488  contradiction  \n",
       "2489     entailment  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data_xnli.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b3aeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>942803</th>\n",
       "      <td>392697</td>\n",
       "      <td>분명히, 캘리포니아는 더 잘 할 수 있고, 더 잘해야 한다.</td>\n",
       "      <td>캘리포니아는 더 잘할 수 없다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942804</th>\n",
       "      <td>392698</td>\n",
       "      <td>한때 유럽에서 가장 아름다운 거리로 여겨졌는데, 이는 원래의 많은 건물들이 교체되었...</td>\n",
       "      <td>그래서 원래의 많은 건물들이 편의점으로 대체되었다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942805</th>\n",
       "      <td>392699</td>\n",
       "      <td>하우스보트는 영국 라지의 전성기의 아름답게 보존된 전통이다.</td>\n",
       "      <td>하우스보트의 전통은 영국 라지가 여전히 강해지는 동안 시작되었다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942806</th>\n",
       "      <td>392700</td>\n",
       "      <td>사망 기사는 그의 평론가의 신디케이트 TV 쇼에서 동료 검토 자 Roger Eber...</td>\n",
       "      <td>부고문은 아름다웠고 연예계에서의 그의 업적에 대해 현물로 쓰여졌다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942807</th>\n",
       "      <td>392701</td>\n",
       "      <td>내가 해야 한다는 걸 알거나, 아니면 누가 하라고 하는 것보다 그녀를 밀고하는 것에...</td>\n",
       "      <td>남편이 요즘 너무 과로해서 이 근처에서 많은 일을 부탁할 용기가 나지 않는다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                          sentence1  \\\n",
       "942803  392697                  분명히, 캘리포니아는 더 잘 할 수 있고, 더 잘해야 한다.   \n",
       "942804  392698  한때 유럽에서 가장 아름다운 거리로 여겨졌는데, 이는 원래의 많은 건물들이 교체되었...   \n",
       "942805  392699                  하우스보트는 영국 라지의 전성기의 아름답게 보존된 전통이다.   \n",
       "942806  392700  사망 기사는 그의 평론가의 신디케이트 TV 쇼에서 동료 검토 자 Roger Eber...   \n",
       "942807  392701  내가 해야 한다는 걸 알거나, 아니면 누가 하라고 하는 것보다 그녀를 밀고하는 것에...   \n",
       "\n",
       "                                          sentence2     gold_label  \n",
       "942803                            캘리포니아는 더 잘할 수 없다.  contradiction  \n",
       "942804                 그래서 원래의 많은 건물들이 편의점으로 대체되었다.        neutral  \n",
       "942805         하우스보트의 전통은 영국 라지가 여전히 강해지는 동안 시작되었다.     entailment  \n",
       "942806        부고문은 아름다웠고 연예계에서의 그의 업적에 대해 현물로 쓰여졌다.        neutral  \n",
       "942807  남편이 요즘 너무 과로해서 이 근처에서 많은 일을 부탁할 용기가 나지 않는다.        neutral  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_snli_xnli.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1a59991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>550147</th>\n",
       "      <td>네 명의 더러운 맨발의 아이들.</td>\n",
       "      <td>4명의 아이들이 '가장 깨끗한 발'로 상을 받았다</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550148</th>\n",
       "      <td>네 명의 더러운 맨발의 아이들.</td>\n",
       "      <td>네 명의 노숙자 아이들이 신발을 도둑맞아서 그들의 발이 더러워졌다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550149</th>\n",
       "      <td>한 남자가 아름다운 푸른 물에서 바디슈트를 입고 서핑을 하고 있다.</td>\n",
       "      <td>바디슈트를 입은 남자가 서핑 대회에 참가하고 있다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550150</th>\n",
       "      <td>한 남자가 아름다운 푸른 물에서 바디슈트를 입고 서핑을 하고 있다.</td>\n",
       "      <td>비즈니스 슈트를 입은 남자가 이사회로 향하고 있다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550151</th>\n",
       "      <td>한 남자가 아름다운 푸른 물에서 바디슈트를 입고 서핑을 하고 있다.</td>\n",
       "      <td>아름다운 푸른 물 위에는 바디슈트를 입은 남자가 서핑을 하고 있다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sentence1  \\\n",
       "550147                      네 명의 더러운 맨발의 아이들.   \n",
       "550148                      네 명의 더러운 맨발의 아이들.   \n",
       "550149  한 남자가 아름다운 푸른 물에서 바디슈트를 입고 서핑을 하고 있다.   \n",
       "550150  한 남자가 아름다운 푸른 물에서 바디슈트를 입고 서핑을 하고 있다.   \n",
       "550151  한 남자가 아름다운 푸른 물에서 바디슈트를 입고 서핑을 하고 있다.   \n",
       "\n",
       "                                    sentence2     gold_label  \n",
       "550147            4명의 아이들이 '가장 깨끗한 발'로 상을 받았다  contradiction  \n",
       "550148  네 명의 노숙자 아이들이 신발을 도둑맞아서 그들의 발이 더러워졌다.        neutral  \n",
       "550149           바디슈트를 입은 남자가 서핑 대회에 참가하고 있다.        neutral  \n",
       "550150           비즈니스 슈트를 입은 남자가 이사회로 향하고 있다.  contradiction  \n",
       "550151  아름다운 푸른 물 위에는 바디슈트를 입은 남자가 서핑을 하고 있다.     entailment  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_snli.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "620248b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>392697</th>\n",
       "      <td>분명히, 캘리포니아는 더 잘 할 수 있고, 더 잘해야 한다.</td>\n",
       "      <td>캘리포니아는 더 잘할 수 없다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392698</th>\n",
       "      <td>한때 유럽에서 가장 아름다운 거리로 여겨졌는데, 이는 원래의 많은 건물들이 교체되었...</td>\n",
       "      <td>그래서 원래의 많은 건물들이 편의점으로 대체되었다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392699</th>\n",
       "      <td>하우스보트는 영국 라지의 전성기의 아름답게 보존된 전통이다.</td>\n",
       "      <td>하우스보트의 전통은 영국 라지가 여전히 강해지는 동안 시작되었다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392700</th>\n",
       "      <td>사망 기사는 그의 평론가의 신디케이트 TV 쇼에서 동료 검토 자 Roger Eber...</td>\n",
       "      <td>부고문은 아름다웠고 연예계에서의 그의 업적에 대해 현물로 쓰여졌다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392701</th>\n",
       "      <td>내가 해야 한다는 걸 알거나, 아니면 누가 하라고 하는 것보다 그녀를 밀고하는 것에...</td>\n",
       "      <td>남편이 요즘 너무 과로해서 이 근처에서 많은 일을 부탁할 용기가 나지 않는다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence1  \\\n",
       "392697                  분명히, 캘리포니아는 더 잘 할 수 있고, 더 잘해야 한다.   \n",
       "392698  한때 유럽에서 가장 아름다운 거리로 여겨졌는데, 이는 원래의 많은 건물들이 교체되었...   \n",
       "392699                  하우스보트는 영국 라지의 전성기의 아름답게 보존된 전통이다.   \n",
       "392700  사망 기사는 그의 평론가의 신디케이트 TV 쇼에서 동료 검토 자 Roger Eber...   \n",
       "392701  내가 해야 한다는 걸 알거나, 아니면 누가 하라고 하는 것보다 그녀를 밀고하는 것에...   \n",
       "\n",
       "                                          sentence2     gold_label  \n",
       "392697                            캘리포니아는 더 잘할 수 없다.  contradiction  \n",
       "392698                 그래서 원래의 많은 건물들이 편의점으로 대체되었다.        neutral  \n",
       "392699         하우스보트의 전통은 영국 라지가 여전히 강해지는 동안 시작되었다.     entailment  \n",
       "392700        부고문은 아름다웠고 연예계에서의 그의 업적에 대해 현물로 쓰여졌다.        neutral  \n",
       "392701  남편이 요즘 너무 과로해서 이 근처에서 많은 일을 부탁할 용기가 나지 않는다.        neutral  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_xnli.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e593e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>한 사람이 경쟁을 위해 말을 훈련시키고 있다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>한 사람이 식당에서 오믈렛을 주문하고 있다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>사람은 야외에서 말을 타고 있다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>카메라에 웃고 손을 흔드는 아이들</td>\n",
       "      <td>그들은 부모님을 보고 웃고 있다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>카메라에 웃고 손을 흔드는 아이들</td>\n",
       "      <td>아이들이 있다</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392697</th>\n",
       "      <td>분명히, 캘리포니아는 더 잘 할 수 있고, 더 잘해야 한다.</td>\n",
       "      <td>캘리포니아는 더 잘할 수 없다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392698</th>\n",
       "      <td>한때 유럽에서 가장 아름다운 거리로 여겨졌는데, 이는 원래의 많은 건물들이 교체되었...</td>\n",
       "      <td>그래서 원래의 많은 건물들이 편의점으로 대체되었다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392699</th>\n",
       "      <td>하우스보트는 영국 라지의 전성기의 아름답게 보존된 전통이다.</td>\n",
       "      <td>하우스보트의 전통은 영국 라지가 여전히 강해지는 동안 시작되었다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392700</th>\n",
       "      <td>사망 기사는 그의 평론가의 신디케이트 TV 쇼에서 동료 검토 자 Roger Eber...</td>\n",
       "      <td>부고문은 아름다웠고 연예계에서의 그의 업적에 대해 현물로 쓰여졌다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392701</th>\n",
       "      <td>내가 해야 한다는 걸 알거나, 아니면 누가 하라고 하는 것보다 그녀를 밀고하는 것에...</td>\n",
       "      <td>남편이 요즘 너무 과로해서 이 근처에서 많은 일을 부탁할 용기가 나지 않는다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942854 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence1  \\\n",
       "0                              말을 탄 사람이 고장난 비행기 위로 뛰어오른다.   \n",
       "1                              말을 탄 사람이 고장난 비행기 위로 뛰어오른다.   \n",
       "2                              말을 탄 사람이 고장난 비행기 위로 뛰어오른다.   \n",
       "3                                      카메라에 웃고 손을 흔드는 아이들   \n",
       "4                                      카메라에 웃고 손을 흔드는 아이들   \n",
       "...                                                   ...   \n",
       "392697                  분명히, 캘리포니아는 더 잘 할 수 있고, 더 잘해야 한다.   \n",
       "392698  한때 유럽에서 가장 아름다운 거리로 여겨졌는데, 이는 원래의 많은 건물들이 교체되었...   \n",
       "392699                  하우스보트는 영국 라지의 전성기의 아름답게 보존된 전통이다.   \n",
       "392700  사망 기사는 그의 평론가의 신디케이트 TV 쇼에서 동료 검토 자 Roger Eber...   \n",
       "392701  내가 해야 한다는 걸 알거나, 아니면 누가 하라고 하는 것보다 그녀를 밀고하는 것에...   \n",
       "\n",
       "                                          sentence2     gold_label  \n",
       "0                         한 사람이 경쟁을 위해 말을 훈련시키고 있다.        neutral  \n",
       "1                          한 사람이 식당에서 오믈렛을 주문하고 있다.  contradiction  \n",
       "2                                사람은 야외에서 말을 타고 있다.     entailment  \n",
       "3                                 그들은 부모님을 보고 웃고 있다        neutral  \n",
       "4                                           아이들이 있다     entailment  \n",
       "...                                             ...            ...  \n",
       "392697                            캘리포니아는 더 잘할 수 없다.  contradiction  \n",
       "392698                 그래서 원래의 많은 건물들이 편의점으로 대체되었다.        neutral  \n",
       "392699         하우스보트의 전통은 영국 라지가 여전히 강해지는 동안 시작되었다.     entailment  \n",
       "392700        부고문은 아름다웠고 연예계에서의 그의 업적에 대해 현물로 쓰여졌다.        neutral  \n",
       "392701  남편이 요즘 너무 과로해서 이 근처에서 많은 일을 부탁할 용기가 나지 않는다.        neutral  \n",
       "\n",
       "[942854 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_snli.append(train_data_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1b3e698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>한 사람이 경쟁을 위해 말을 훈련시키고 있다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>한 사람이 식당에서 오믈렛을 주문하고 있다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>사람은 야외에서 말을 타고 있다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>카메라에 웃고 손을 흔드는 아이들</td>\n",
       "      <td>그들은 부모님을 보고 웃고 있다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>카메라에 웃고 손을 흔드는 아이들</td>\n",
       "      <td>아이들이 있다</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942849</th>\n",
       "      <td>392697</td>\n",
       "      <td>분명히, 캘리포니아는 더 잘 할 수 있고, 더 잘해야 한다.</td>\n",
       "      <td>캘리포니아는 더 잘할 수 없다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942850</th>\n",
       "      <td>392698</td>\n",
       "      <td>한때 유럽에서 가장 아름다운 거리로 여겨졌는데, 이는 원래의 많은 건물들이 교체되었...</td>\n",
       "      <td>그래서 원래의 많은 건물들이 편의점으로 대체되었다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942851</th>\n",
       "      <td>392699</td>\n",
       "      <td>하우스보트는 영국 라지의 전성기의 아름답게 보존된 전통이다.</td>\n",
       "      <td>하우스보트의 전통은 영국 라지가 여전히 강해지는 동안 시작되었다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942852</th>\n",
       "      <td>392700</td>\n",
       "      <td>사망 기사는 그의 평론가의 신디케이트 TV 쇼에서 동료 검토 자 Roger Eber...</td>\n",
       "      <td>부고문은 아름다웠고 연예계에서의 그의 업적에 대해 현물로 쓰여졌다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942853</th>\n",
       "      <td>392701</td>\n",
       "      <td>내가 해야 한다는 걸 알거나, 아니면 누가 하라고 하는 것보다 그녀를 밀고하는 것에...</td>\n",
       "      <td>남편이 요즘 너무 과로해서 이 근처에서 많은 일을 부탁할 용기가 나지 않는다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942854 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                          sentence1  \\\n",
       "0            0                         말을 탄 사람이 고장난 비행기 위로 뛰어오른다.   \n",
       "1            1                         말을 탄 사람이 고장난 비행기 위로 뛰어오른다.   \n",
       "2            2                         말을 탄 사람이 고장난 비행기 위로 뛰어오른다.   \n",
       "3            3                                 카메라에 웃고 손을 흔드는 아이들   \n",
       "4            4                                 카메라에 웃고 손을 흔드는 아이들   \n",
       "...        ...                                                ...   \n",
       "942849  392697                  분명히, 캘리포니아는 더 잘 할 수 있고, 더 잘해야 한다.   \n",
       "942850  392698  한때 유럽에서 가장 아름다운 거리로 여겨졌는데, 이는 원래의 많은 건물들이 교체되었...   \n",
       "942851  392699                  하우스보트는 영국 라지의 전성기의 아름답게 보존된 전통이다.   \n",
       "942852  392700  사망 기사는 그의 평론가의 신디케이트 TV 쇼에서 동료 검토 자 Roger Eber...   \n",
       "942853  392701  내가 해야 한다는 걸 알거나, 아니면 누가 하라고 하는 것보다 그녀를 밀고하는 것에...   \n",
       "\n",
       "                                          sentence2     gold_label  \n",
       "0                         한 사람이 경쟁을 위해 말을 훈련시키고 있다.        neutral  \n",
       "1                          한 사람이 식당에서 오믈렛을 주문하고 있다.  contradiction  \n",
       "2                                사람은 야외에서 말을 타고 있다.     entailment  \n",
       "3                                 그들은 부모님을 보고 웃고 있다        neutral  \n",
       "4                                           아이들이 있다     entailment  \n",
       "...                                             ...            ...  \n",
       "942849                            캘리포니아는 더 잘할 수 없다.  contradiction  \n",
       "942850                 그래서 원래의 많은 건물들이 편의점으로 대체되었다.        neutral  \n",
       "942851         하우스보트의 전통은 영국 라지가 여전히 강해지는 동안 시작되었다.     entailment  \n",
       "942852        부고문은 아름다웠고 연예계에서의 그의 업적에 대해 현물로 쓰여졌다.        neutral  \n",
       "942853  남편이 요즘 너무 과로해서 이 근처에서 많은 일을 부탁할 용기가 나지 않는다.        neutral  \n",
       "\n",
       "[942854 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_data_snli.append(train_data_xnli)\n",
    "\n",
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a831f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Tokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", cache_dir='bert-ckpt', do_lower_case=False)\n",
    "\n",
    "def bert_tokenizer_v2(sent1, sent2, MAX_LEN):\n",
    "    \n",
    "    # For Two sentence input\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent1,\n",
    "        text_pair = sent2,\n",
    "        add_special_tokens = True, # '[CLS]', '[SEP]' 추가\n",
    "        max_length = MAX_LEN, # 48     # pad & truncate\n",
    "        pad_to_max_length = True,\n",
    "        truncation=True,\n",
    "        return_attention_mask = True)\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask']\n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0541b116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  9251 10622  9847 97802  8888 13890 33305  9379 25549 12310  9619\n",
      " 11261  9150 12965 28188 66346   119   102  9405 61250 10892  9538 78705\n",
      " 11489  9251 10622  9845 11664 11506   119   102     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[CLS] 말을 탄 사람이 고장난 비행기 위로 뛰어오른다. [SEP] 사람은 야외에서 말을 타고 있다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "942808\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "\n",
    "for sent1, sent2 in zip(train_data_snli_xnli['sentence1'], train_data_snli_xnli['sentence2']):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer_v2(sent1, sent2, MAX_LEN)\n",
    "        \n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(sent1, sent2, sep='\\t')\n",
    "        pass\n",
    "    \n",
    "train_snli_xnli_input_ids = np.array(input_ids, dtype=int)\n",
    "train_snli_xnli_attention_masks = np.array(attention_masks, dtype=int)\n",
    "train_snli_xnli_type_ids = np.array(token_type_ids, dtype=int)\n",
    "train_snli_xnli_inputs = (train_snli_xnli_input_ids, train_snli_xnli_attention_masks, train_snli_xnli_type_ids)\n",
    "\n",
    "\n",
    "input_id = train_snli_xnli_input_ids[2]\n",
    "attention_mask = train_snli_xnli_attention_masks[2]\n",
    "token_type_id = train_snli_xnli_type_ids[2]\n",
    "\n",
    "print(input_id)\n",
    "print(attention_mask)\n",
    "print(token_type_id)\n",
    "print(tokenizer.decode(input_id))\n",
    "\n",
    "print()\n",
    "print(len(train_snli_xnli_input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0db39c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['말',\n",
       " '##을',\n",
       " '탄',\n",
       " '사람이',\n",
       " '고',\n",
       " '##장',\n",
       " '##난',\n",
       " '비',\n",
       " '##행',\n",
       " '##기',\n",
       " '위',\n",
       " '##로',\n",
       " '뛰',\n",
       " '##어',\n",
       " '##오',\n",
       " '##른다',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"말을 탄 사람이 고장난 비행기 위로 뛰어오른다.\") # 17길이 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd165ef",
   "metadata": {},
   "source": [
    "# DEV SET Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0923d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저를 제외하고는 5장에서 처리한 방식과 유사하게 접근\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "\n",
    "for sent1, sent2 in zip(dev_data_xnli['sentence1'], dev_data_xnli['sentence2']):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer_v2(sent1, sent2, MAX_LEN)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(sent1, sent2)\n",
    "        pass\n",
    "    \n",
    "dev_xnli_input_ids = np.array(input_ids, dtype=int)\n",
    "dev_xnli_attention_masks = np.array(attention_masks, dtype=int)\n",
    "dev_xnli_type_ids = np.array(token_type_ids, dtype=int)\n",
    "dev_xnli_inputs = (dev_xnli_input_ids, dev_xnli_attention_masks, dev_xnli_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280f73a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train labels: 942808, # dev labels: 2490\n"
     ]
    }
   ],
   "source": [
    "# Label을 Neutral, Contradiction, Entailment 에서 숫자형으로 변경\n",
    "label_dict = {\"entailment\":0, \"contradiction\":1, \"neutral\":2}\n",
    "\n",
    "def convert_int(label):\n",
    "    num_label = label_dict[label]\n",
    "    return num_label\n",
    "\n",
    "train_data_snli_xnli['gold_label_int'] = train_data_snli_xnli['gold_label'].apply(convert_int)\n",
    "train_data_labels = np.array(train_data_snli_xnli['gold_label_int'], dtype=int)\n",
    "\n",
    "dev_data_xnli['gold_label_int'] = dev_data_xnli['gold_label'].apply(convert_int)\n",
    "dev_data_labels = np.array(dev_data_xnli['gold_label_int'], dtype=int)\n",
    "\n",
    "print(\"# train labels: {}, # dev labels: {}\".format(len(train_data_labels), len(dev_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50f47a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>gold_label_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>한 사람이 경쟁을 위해 말을 훈련시키고 있다.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>한 사람이 식당에서 오믈렛을 주문하고 있다.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>사람은 야외에서 말을 타고 있다.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>카메라에 웃고 손을 흔드는 아이들</td>\n",
       "      <td>그들은 부모님을 보고 웃고 있다</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>카메라에 웃고 손을 흔드는 아이들</td>\n",
       "      <td>아이들이 있다</td>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                   sentence1                  sentence2  \\\n",
       "0      0  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.  한 사람이 경쟁을 위해 말을 훈련시키고 있다.   \n",
       "1      1  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.   한 사람이 식당에서 오믈렛을 주문하고 있다.   \n",
       "2      2  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.         사람은 야외에서 말을 타고 있다.   \n",
       "3      3          카메라에 웃고 손을 흔드는 아이들          그들은 부모님을 보고 웃고 있다   \n",
       "4      4          카메라에 웃고 손을 흔드는 아이들                    아이들이 있다   \n",
       "\n",
       "      gold_label  gold_label_int  \n",
       "0        neutral               2  \n",
       "1  contradiction               1  \n",
       "2     entailment               0  \n",
       "3        neutral               2  \n",
       "4     entailment               0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_snli_xnli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2154d8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>gold_label_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그리고 그가 말했다, \"엄마, 저 왔어요.\"</td>\n",
       "      <td>그는 학교 버스가 그를 내려주자마자 엄마에게 전화를 걸었다.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그리고 그가 말했다, \"엄마, 저 왔어요.\"</td>\n",
       "      <td>그는 한마디도 하지 않았다.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그리고 그가 말했다, \"엄마, 저 왔어요.\"</td>\n",
       "      <td>그는 엄마에게 집에 갔다고 말했다.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 ...</td>\n",
       "      <td>나는 워싱턴에 가본 적이 없어서 거기 배정을 받았을 때 그 장소를 찾으려다가 길을 ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 ...</td>\n",
       "      <td>워싱턴으로 진군하면서 해야 할 일이 무엇인지 정확히 알고 있었다.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0                           그리고 그가 말했다, \"엄마, 저 왔어요.\"   \n",
       "1                           그리고 그가 말했다, \"엄마, 저 왔어요.\"   \n",
       "2                           그리고 그가 말했다, \"엄마, 저 왔어요.\"   \n",
       "3  내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 ...   \n",
       "4  내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 ...   \n",
       "\n",
       "                                           sentence2     gold_label  \\\n",
       "0                  그는 학교 버스가 그를 내려주자마자 엄마에게 전화를 걸었다.        neutral   \n",
       "1                                    그는 한마디도 하지 않았다.  contradiction   \n",
       "2                                그는 엄마에게 집에 갔다고 말했다.     entailment   \n",
       "3  나는 워싱턴에 가본 적이 없어서 거기 배정을 받았을 때 그 장소를 찾으려다가 길을 ...        neutral   \n",
       "4               워싱턴으로 진군하면서 해야 할 일이 무엇인지 정확히 알고 있었다.  contradiction   \n",
       "\n",
       "   gold_label_int  \n",
       "0               2  \n",
       "1               1  \n",
       "2               0  \n",
       "3               2  \n",
       "4               1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data_xnli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0debc8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "class TFBertClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertClassifier, self).__init__()\n",
    "        \n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(num_class, # 3\n",
    "                                               kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range),\n",
    "                                               name=\"classifier\")\n",
    "        \n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "        \n",
    "        # outputs: sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output, training=training)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# 모델 선언: TFBertModel 기반 다중 Classifier\n",
    "cls_model = TFBertClassifier(model_name=\"bert-base-multilingual-cased\",\n",
    "                            dir_path='bert_ckpt',\n",
    "                            num_class=3) # 0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d1d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 준비: 최적화, 손실값, 정확도 선언 & 모델 컴파일 \n",
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "cls_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47fe4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 942808 쌍에서 앞 1000개만 떼서 보기 --> 학습 시간 감소 목적\n",
    "train_snli_xnli_inputs_short = (train_snli_xnli_input_ids[:1000], \n",
    "                               train_snli_xnli_attention_masks[:1000],\n",
    "                               train_snli_xnli_type_ids[:1000])\n",
    "\n",
    "train_data_labels_short = train_data_labels[:1000]\n",
    "\n",
    "# 2490 검증 데이터에서 앞 100개만! \n",
    "dev_xnli_inputs_short = (dev_xnli_input_ids[:100],\n",
    "                        dev_xnli_attention_masks[:100], \n",
    "                         dev_xnli_type_ids[:100])\n",
    "\n",
    "dev_data_labels_short = dev_data_labels[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0428adcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_out/KOR\\tf2_KorNLI -- Folder already exists \n",
      "\n",
      "Epoch 1/3\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.0442 - accuracy: 0.4300 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.43000, saving model to ./data_out/KOR\\tf2_KorNLI\\weights.h5\n",
      "32/32 [==============================] - 442s 13s/step - loss: 1.0442 - accuracy: 0.4300 - val_loss: 1.0406 - val_accuracy: 0.4300\n",
      "Epoch 2/3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.9049 - accuracy: 0.5670 \n",
      "Epoch 2: val_accuracy improved from 0.43000 to 0.49000, saving model to ./data_out/KOR\\tf2_KorNLI\\weights.h5\n",
      "32/32 [==============================] - 509s 15s/step - loss: 0.9049 - accuracy: 0.5670 - val_loss: 1.0536 - val_accuracy: 0.4900\n",
      "Epoch 3/3\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7605 - accuracy: 0.6540 \n",
      "Epoch 3: val_accuracy did not improve from 0.49000\n",
      "32/32 [==============================] - 546s 17s/step - loss: 0.7605 - accuracy: 0.6540 - val_loss: 1.0759 - val_accuracy: 0.4200\n",
      "{'loss': [1.0442132949829102, 0.9049372673034668, 0.7605381608009338], 'accuracy': [0.4300000071525574, 0.5669999718666077, 0.6539999842643738], 'val_loss': [1.0406177043914795, 1.0535869598388672, 1.0759460926055908], 'val_accuracy': [0.4300000071525574, 0.49000000953674316, 0.41999998688697815]}\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행\n",
    "model_name = 'tf2_KorNLI'\n",
    "\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=2)\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# 학습, 검증 시작\n",
    "history = cls_model.fit(train_snli_xnli_inputs_short, train_data_labels_short,\n",
    "                       epochs=NUM_EPOCHS,\n",
    "                       # validation_split=VALID_SPLIT (검증비율)\n",
    "                       # 대신에, 따로 만들어둔 검증 데이터 사용\n",
    "                       validation_data=(dev_xnli_inputs_short, dev_data_labels_short),\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       callbacks=[earlystop_callback, cp_callback])\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520d002",
   "metadata": {},
   "source": [
    "(학습데이터만, 검증데이터 그대로 2480개) 1000개로 짤랐더니 313 배치 개수, 시간 약 40분 소요 (한 epoch 당)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45b2f0",
   "metadata": {},
   "source": [
    "학습데이터 1000개, 검증데이터 100개로 짤랏떠니, 32 배치 개수, 시간 약 4분으로 줄음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c79d99",
   "metadata": {},
   "source": [
    "최종 val_accuracy: 0.41 밖에 안됨 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1fe36f",
   "metadata": {},
   "source": [
    "# KorNLI Test Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "909717c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sents: 5010, # labels: 5010\n",
      "10/10 [==============================] - 342s 36s/step - loss: 1.1357 - accuracy: 0.4329\n",
      "test loss, test acc:  [1.1357272863388062, 0.43293413519859314]\n"
     ]
    }
   ],
   "source": [
    "# Load Test dataset\n",
    "TEST_XNLI_DF = os.path.join(DATA_IN_PATH, 'KorNLI', 'xnli.test.ko.tsv')\n",
    "\n",
    "test_data_xnli = pd.read_csv(TEST_XNLI_DF, header=0, delimiter = '\\t', quoting = 3)\n",
    "test_data_xnli = test_data_xnli.dropna()\n",
    "test_data_xnli.head()\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "\n",
    "for sent1, sent2 in zip(test_data_xnli['sentence1'], test_data_xnli['sentence2']):\n",
    "    \n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer_v2(sent1, sent2, MAX_LEN)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(sent1, sent2)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "test_xnli_input_ids = np.array(input_ids, dtype=int)\n",
    "test_xnli_attention_masks = np.array(attention_masks, dtype=int)\n",
    "test_xnli_type_ids = np.array(token_type_ids, dtype=int)\n",
    "test_xnli_inputs = (test_xnli_input_ids, test_xnli_attention_masks, test_xnli_type_ids)\n",
    "\n",
    "test_data_xnli[\"gold_label_int\"] = test_data_xnli[\"gold_label\"].apply(convert_int)\n",
    "test_data_xnli_labels = np.array(test_data_xnli['gold_label_int'], dtype=int)\n",
    "\n",
    "print(\"# sents: {}, # labels: {}\".format(len(test_xnli_input_ids), len(test_data_xnli_labels)))\n",
    "\n",
    "results = cls_model.evaluate(test_xnli_inputs, test_data_xnli_labels, batch_size=512)\n",
    "print(\"test loss, test acc: \", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
